{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains over 6000 spotify tracks ranging from the 1960s through the 2010s. Each track has been assigned a target variable '1' or '0' depending on if the track made it into the Billboard Top 100 charts. We will try to train a machine learning model to be able to predict a song's hit potential. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>uri</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>chorus_hit</th>\n",
       "      <th>sections</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jealous Kind Of Fella</td>\n",
       "      <td>Garland Green</td>\n",
       "      <td>spotify:track:1dtKN6wwlolkM8XZy2y9C1</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.620</td>\n",
       "      <td>3</td>\n",
       "      <td>-7.727</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>0.845</td>\n",
       "      <td>185.655</td>\n",
       "      <td>173533</td>\n",
       "      <td>3</td>\n",
       "      <td>32.94975</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Initials B.B.</td>\n",
       "      <td>Serge Gainsbourg</td>\n",
       "      <td>spotify:track:5hjsmSnUefdUqzsDogisiX</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.505</td>\n",
       "      <td>3</td>\n",
       "      <td>-12.475</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.107000</td>\n",
       "      <td>0.1760</td>\n",
       "      <td>0.797</td>\n",
       "      <td>101.801</td>\n",
       "      <td>213613</td>\n",
       "      <td>4</td>\n",
       "      <td>48.82510</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Melody Twist</td>\n",
       "      <td>Lord Melody</td>\n",
       "      <td>spotify:track:6uk8tI6pwxxdVTNlNOJeJh</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.649</td>\n",
       "      <td>5</td>\n",
       "      <td>-13.392</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.908</td>\n",
       "      <td>115.940</td>\n",
       "      <td>223960</td>\n",
       "      <td>4</td>\n",
       "      <td>37.22663</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Bomba Sonó</td>\n",
       "      <td>Celia Cruz</td>\n",
       "      <td>spotify:track:7aNjMJ05FvUXACPWZ7yJmv</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.545</td>\n",
       "      <td>7</td>\n",
       "      <td>-12.058</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.967</td>\n",
       "      <td>105.592</td>\n",
       "      <td>157907</td>\n",
       "      <td>4</td>\n",
       "      <td>24.75484</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uravu Solla</td>\n",
       "      <td>P. Susheela</td>\n",
       "      <td>spotify:track:1rQ0clvgkzWr001POOPJWx</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.765</td>\n",
       "      <td>11</td>\n",
       "      <td>-3.515</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.2130</td>\n",
       "      <td>0.906</td>\n",
       "      <td>114.617</td>\n",
       "      <td>245600</td>\n",
       "      <td>4</td>\n",
       "      <td>21.79874</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   track            artist  \\\n",
       "0  Jealous Kind Of Fella     Garland Green   \n",
       "1          Initials B.B.  Serge Gainsbourg   \n",
       "2           Melody Twist       Lord Melody   \n",
       "3          Mi Bomba Sonó        Celia Cruz   \n",
       "4            Uravu Solla       P. Susheela   \n",
       "\n",
       "                                    uri  danceability  energy  key  loudness  \\\n",
       "0  spotify:track:1dtKN6wwlolkM8XZy2y9C1         0.417   0.620    3    -7.727   \n",
       "1  spotify:track:5hjsmSnUefdUqzsDogisiX         0.498   0.505    3   -12.475   \n",
       "2  spotify:track:6uk8tI6pwxxdVTNlNOJeJh         0.657   0.649    5   -13.392   \n",
       "3  spotify:track:7aNjMJ05FvUXACPWZ7yJmv         0.590   0.545    7   -12.058   \n",
       "4  spotify:track:1rQ0clvgkzWr001POOPJWx         0.515   0.765   11    -3.515   \n",
       "\n",
       "   mode  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "0     1       0.0403         0.490          0.000000    0.0779    0.845   \n",
       "1     1       0.0337         0.018          0.107000    0.1760    0.797   \n",
       "2     1       0.0380         0.846          0.000004    0.1190    0.908   \n",
       "3     0       0.1040         0.706          0.024600    0.0610    0.967   \n",
       "4     0       0.1240         0.857          0.000872    0.2130    0.906   \n",
       "\n",
       "     tempo  duration_ms  time_signature  chorus_hit  sections  target  \n",
       "0  185.655       173533               3    32.94975         9       1  \n",
       "1  101.801       213613               4    48.82510        10       0  \n",
       "2  115.940       223960               4    37.22663        12       0  \n",
       "3  105.592       157907               4    24.75484         8       0  \n",
       "4  114.617       245600               4    21.79874        14       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = ['dataset-of-60s.csv', 'dataset-of-70s.csv', 'dataset-of-80s.csv', 'dataset-of-90s.csv', 'dataset-of-00s.csv', 'dataset-of-10s.csv']\n",
    "dflist = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(dataset)\n",
    "    dflist.append(df)\n",
    "    \n",
    "df_concat = pd.concat(dflist)\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_concat[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature', 'chorus_hit', 'sections']]\n",
    "y = df_concat['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7302951670450859,\n",
       " 0.729403178722024,\n",
       " 0.7353227375932533,\n",
       " 0.7362147259163153,\n",
       " 0.7343496594226403,\n",
       " 0.7375121634771327]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [50, 100, 150, 200, 250, 300]\n",
    "\n",
    "scorelist = []\n",
    "\n",
    "for estimator in n_estimators:\n",
    "    clf = RandomForestClassifier(n_estimators=estimator, max_depth=2, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scorelist.append(clf.score(X_test, y_test))\n",
    "\n",
    "scorelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7375121634771327"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=300, max_depth=2, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7445958156669216"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first attempt at a model with a relatively basic random forest classifier is getting 73% accuracy on the test set. The score on the train set is not much higher, so this model doesn't seem to be overfitting. Below we'll inspect the feature importances in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danceability : 0.1961608604247969\n",
      "energy : 0.10186251245010265\n",
      "key : 0.0\n",
      "loudness : 0.10804753662129706\n",
      "mode : 0.0012185736458913317\n",
      "speechiness : 0.02482497234444852\n",
      "acousticness : 0.1508940885169172\n",
      "instrumentalness : 0.2650231879735413\n",
      "liveness : 0.0017610270658901823\n",
      "valence : 0.06123975608998724\n",
      "tempo : 0.001843649491325074\n",
      "duration_ms : 0.04616232259887296\n",
      "time_signature : 0.007187765634488112\n",
      "chorus_hit : 0.0013198312574551716\n",
      "sections : 0.032453915884986216\n"
     ]
    }
   ],
   "source": [
    "cols = list(X.columns)\n",
    "features = list(clf.feature_importances_)\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    print(cols[i], ':', features[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While 73% accuracy right away is fairly good, let's see if we can optimize the hyperparameters more with a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 432 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1296 out of 1296 | elapsed: 356.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [80, 90, 100, 110],\n",
       "                         'max_features': [2, 3, 5],\n",
       "                         'min_samples_leaf': [3, 4, 5],\n",
       "                         'min_samples_split': [8, 10, 12],\n",
       "                         'n_estimators': [100, 200, 300, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3, 5],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 100,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=100, max_features=3, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=3, min_samples_split=8,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = grid_search.best_estimator_\n",
    "\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7895718456049302"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9637519983318273"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8037510398547985"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf2.predict(X_test)\n",
    "\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danceability : 0.1090932704107315\n",
      "energy : 0.0840647059812641\n",
      "key : 0.02313629298791549\n",
      "loudness : 0.07427836670198854\n",
      "mode : 0.010076323891850083\n",
      "speechiness : 0.07038902012393433\n",
      "acousticness : 0.12025238423451987\n",
      "instrumentalness : 0.19726142550504241\n",
      "liveness : 0.042531273133259564\n",
      "valence : 0.06892994518585582\n",
      "tempo : 0.04592572652586165\n",
      "duration_ms : 0.07271957823320976\n",
      "time_signature : 0.005067301791247238\n",
      "chorus_hit : 0.04171871710088423\n",
      "sections : 0.0345556681924354\n"
     ]
    }
   ],
   "source": [
    "cols = list(X.columns)\n",
    "features = list(clf2.feature_importances_)\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    print(cols[i], ':', features[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this model got 78% accuracy on the test set, the 96% accuracy on training set indicates that it has been overfit. We'll try reducing the max features and min_samples_split and see if this fixes the overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=90, max_features=2, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=3, min_samples_split=5,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = RandomForestClassifier(max_depth=90, max_features=2, min_samples_leaf=3, min_samples_split=5, bootstrap=True, n_estimators=1000)\n",
    "clf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7877067791112553"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9633349551678598"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we still have a significant amount of overfitting. Let's try using and XGBoost model instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3840 candidates, totalling 11520 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 11520 out of 11520 | elapsed: 563.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=None, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_l...\n",
       "                                     scale_pos_weight=1, seed=None, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'colsample_bytree': [0.3, 0.4, 0.5, 0.7],\n",
       "                         'eta': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
       "                         'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                         'max_depth': [3, 4, 5, 6, 8, 10, 12, 15],\n",
       "                         'min_child_weight': [1, 3, 5, 7]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_log_loss', verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4 = xgb.XGBClassifier()\n",
    "parameters = {\n",
    "     \"eta\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    "     \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "     \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "     \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "     \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "     }\n",
    "\n",
    "grid = GridSearchCV(clf4,\n",
    "                    parameters, \n",
    "                    scoring=\"neg_log_loss\",\n",
    "                    cv=3, verbose=1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7,\n",
       " 'eta': 0.05,\n",
       " 'gamma': 0.3,\n",
       " 'max_depth': 8,\n",
       " 'min_child_weight': 5}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7, eta=0.05, gamma=0.3,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
       "              min_child_weight=5, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5 = grid.best_estimator_\n",
    "clf5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7873824197210509"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8517411552095642"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7870413295136355"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, precision_score, roc_curve, f1_score\n",
    "\n",
    "y_pred = clf5.predict(X_test)\n",
    "\n",
    "roc_score = roc_auc_score(y_test, y_pred)\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4385, 1752],\n",
       "       [ 870, 5325]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7524374735057228"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score = precision_score(y_test, y_pred)\n",
    "precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8024412296564195"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting fairly high accuracy with less overfitting on the whole dataset now. However, during exploratory data analysis we noticed differences in the features for each decade. We'll test the accuracy of this model by decade, rather than on the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df60s = pd.read_csv('dataset-of-60s.csv')\n",
    "\n",
    "X60s = df60s[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature', 'chorus_hit', 'sections']]\n",
    "y60s = df60s['target']\n",
    "\n",
    "X_train60s, X_test60s, y_train60s, y_test60s = train_test_split(X60s, y60s, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7705360586193598"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.fit(X_train60s, y_train60s)\n",
    "clf5.score(X_test60s, y_test60s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9299057695486858"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.score(X_train60s, y_train60s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7706084799305138"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred60s = clf5.predict(X_test60s)\n",
    "\n",
    "roc60s = roc_auc_score(y_test60s, y_pred60s)\n",
    "roc60s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 919,  379],\n",
       "       [ 216, 1079]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion60s = confusion_matrix(y_test60s, y_pred60s)\n",
    "confusion60s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df70s = pd.read_csv('dataset-of-70s.csv')\n",
    "\n",
    "X70s = df70s[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature', 'chorus_hit', 'sections']]\n",
    "y70s = df70s['target']\n",
    "\n",
    "X_train70s, X_test70s, y_train70s, y_test70s = train_test_split(X70s, y70s, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7618025751072961"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.fit(X_train70s, y_train70s)\n",
    "clf5.score(X_test70s, y_test70s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.score(X_train70s, y_train70s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df80s = pd.read_csv('dataset-of-80s.csv')\n",
    "\n",
    "X80s = df80s[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature', 'chorus_hit', 'sections']]\n",
    "y80s = df80s['target']\n",
    "\n",
    "X_train80s, X_test80s, y_train80s, y_test80s = train_test_split(X80s, y80s, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.804630969609262"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.fit(X_train80s, y_train80s)\n",
    "clf5.score(X_test80s, y_test80s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9404343329886247"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.score(X_train80s, y_train80s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df90s = pd.read_csv('dataset-of-60s.csv')\n",
    "\n",
    "X90s = df90s[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature', 'chorus_hit', 'sections']]\n",
    "y90s = df90s['target']\n",
    "\n",
    "X_train90s, X_test90s, y_train90s, y_test90s = train_test_split(X90s, y90s, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7705360586193598"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.fit(X_train90s, y_train90s)\n",
    "clf5.score(X_test90s, y_test90s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9299057695486858"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.score(X_train90s, y_train90s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df00s = pd.read_csv('dataset-of-00s.csv')\n",
    "\n",
    "X00s = df00s[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature', 'chorus_hit', 'sections']]\n",
    "y00s = df00s['target']\n",
    "\n",
    "X_train00s, X_test00s, y_train00s, y_test00s = train_test_split(X00s, y00s, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8513053348467651"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.fit(X_train00s, y_train00s)\n",
    "clf5.score(X_test00s, y_test00s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9559610705596107"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.score(X_train00s, y_train00s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10s = pd.read_csv('dataset-of-10s.csv')\n",
    "\n",
    "X10s = df10s[['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms', 'time_signature', 'chorus_hit', 'sections']]\n",
    "y10s = df10s['target']\n",
    "\n",
    "X_train10s, X_test10s, y_train10s, y_test10s = train_test_split(X10s, y10s, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8479166666666667"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.fit(X_train10s, y_train10s)\n",
    "clf5.score(X_test10s, y_test10s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9519874944171505"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.score(X_train10s, y_train10s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall we are getting fairly high accuracy scores by decade, however the accuracy scores are all about 10% higher on the training data. We'll try a slightly different model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7759487512163478"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6 = xgb.XGBClassifier(colsample_bytree=0.5, eta=0.05, gamma=0.3, max_depth=3, min_child_weight=0.5)\n",
    "\n",
    "clf6.fit(X_train, y_train)\n",
    "clf6.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8017854190775334"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7827317763623496"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred6 = clf6.predict(X_test)\n",
    "f1_score(y_test, y_pred6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.763208638642499"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6.fit(X_train90s, y_train90s)\n",
    "clf6.score(X_test90s, y_test90s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8017854190775334"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6.score(X_train90s, y_train90s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we lost a bit of accuracy, this model has significantly less overfitting on the entire dataset. I also tested it on the 90s only data, as the original model overfit the most on that data. This resulted in a .01% accuracy loss but a much less overfit model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danceability : 0.10043808\n",
      "energy : 0.0479939\n",
      "key : 0.020840691\n",
      "loudness : 0.04576259\n",
      "mode : 0.07882381\n",
      "speechiness : 0.05622998\n",
      "acousticness : 0.11864295\n",
      "instrumentalness : 0.25530356\n",
      "liveness : 0.02467498\n",
      "valence : 0.043647353\n",
      "tempo : 0.027719742\n",
      "duration_ms : 0.061845098\n",
      "time_signature : 0.05478216\n",
      "chorus_hit : 0.02297637\n",
      "sections : 0.040318668\n"
     ]
    }
   ],
   "source": [
    "cols = list(X.columns)\n",
    "features = list(clf5.feature_importances_)\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    print(cols[i], ':', features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danceability : 0.11059045\n",
      "energy : 0.051418554\n",
      "key : 0.010074946\n",
      "loudness : 0.06979672\n",
      "mode : 0.048084114\n",
      "speechiness : 0.06723784\n",
      "acousticness : 0.13022204\n",
      "instrumentalness : 0.3213578\n",
      "liveness : 0.012752331\n",
      "valence : 0.037447594\n",
      "tempo : 0.01568847\n",
      "duration_ms : 0.062776536\n",
      "time_signature : 0.020031685\n",
      "chorus_hit : 0.0072689927\n",
      "sections : 0.03525188\n"
     ]
    }
   ],
   "source": [
    "cols = list(X.columns)\n",
    "features = list(clf6.feature_importances_)\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    print(cols[i], ':', features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.763208638642499"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6.fit(X_train60s, y_train60s)\n",
    "clf6.score(X_test60s, y_test60s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8017854190775334"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6.score(X_train60s, y_train60s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7759487512163478"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6.fit(X_train, y_train)\n",
    "clf6.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf6.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7941592788497356"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7755498180304096"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-430e012b2078>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf60s = clf6.fit(X_train60s, y_train60s)\n",
    "clf70s = clf6.fit(X_train70s, y_train70s)\n",
    "clf80s = clf6.fit(X_train80s, y_train80s)\n",
    "clf90s = clf6.fit(X_train90s, y_train90s)\n",
    "clf00s = clf6.fit(X_train00s, y_train00s)\n",
    "clf10s = clf6.fit(X_train10s, y_train10s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danceability : 0.07090861\n",
      "energy : 0.08476231\n",
      "key : 0.013301995\n",
      "loudness : 0.10419984\n",
      "mode : 0.021957884\n",
      "speechiness : 0.03284651\n",
      "acousticness : 0.104245745\n",
      "instrumentalness : 0.36600888\n",
      "liveness : 0.017663071\n",
      "valence : 0.042346768\n",
      "tempo : 0.018244218\n",
      "duration_ms : 0.066186026\n",
      "time_signature : 0.031244889\n",
      "chorus_hit : 0.010634071\n",
      "sections : 0.015449172\n"
     ]
    }
   ],
   "source": [
    "cols = list(X.columns)\n",
    "features = list(clf60s.feature_importances_)\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    print(cols[i], ':', features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danceability : 0.07090861\n",
      "energy : 0.08476231\n",
      "key : 0.013301995\n",
      "loudness : 0.10419984\n",
      "mode : 0.021957884\n",
      "speechiness : 0.03284651\n",
      "acousticness : 0.104245745\n",
      "instrumentalness : 0.36600888\n",
      "liveness : 0.017663071\n",
      "valence : 0.042346768\n",
      "tempo : 0.018244218\n",
      "duration_ms : 0.066186026\n",
      "time_signature : 0.031244889\n",
      "chorus_hit : 0.010634071\n",
      "sections : 0.015449172\n"
     ]
    }
   ],
   "source": [
    "cols = list(X.columns)\n",
    "features = list(clf70s.feature_importances_)\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    print(cols[i], ':', features[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
